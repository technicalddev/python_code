# -*- coding: utf-8 -*-
"""Step6-NormalisedSigma.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hON5F4Wglfy85BEjEKFTLdoXenV5noLf

# Authentication and Importing Libraries
"""

!pip install pandas-profiling
!pip install --upgrade 'sqlalchemy<2.0'

# Authenticating credentials

from google.colab import auth,files
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()

gc = gspread.authorize(creds)
# gc = gspread.authorize(GoogleCredentials.get_application_default())

# gauth = GoogleAuth()
# gauth.credentials = GoogleCredentials.get_application_default()
# drive = GoogleDrive(gauth)
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Importing all the necessary modules
import pandas as pd
import pandas_profiling
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from pandas.plotting import scatter_matrix
from datetime import datetime,date

from sklearn import metrics
from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler
from sklearn.model_selection import cross_val_score, KFold, train_test_split
from sklearn.linear_model import LogisticRegression, LinearRegression, RidgeCV, LassoCV, Ridge, Lasso
import pandas as pd
pd.options.display.float_format = '{:.4f}'.format
import seaborn as sns
import statsmodels.api as sm
import statsmodels

from sklearn.feature_selection import SelectKBest, chi2, f_classif,f_regression, RFE
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, ExtraTreesClassifier

# VIF Library
from statsmodels.stats.outliers_influence import variance_inflation_factor

# For clustering
from scipy.spatial import distance
from scipy.spatial.distance import cdist
from sklearn.metrics import silhouette_samples, silhouette_score
import sklearn.cluster as sc
from scipy.spatial import distance as d
from sklearn.manifold import TSNE
import plotly.graph_objs as go
pd.set_option('display.max_columns', None)


# PCA
from sklearn.decomposition import PCA
import pylab as pl

# Supervised Learning
from sklearn.tree import DecisionTreeRegressor

# Decision Tree
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import mean_squared_error
from sklearn.tree import plot_tree
import gspread_dataframe as gd


# Visualizations
import matplotlib.cm as cm
# %matplotlib inline

#!pip install dython
#from dython import nominal

!pip install pymysql

#initialize mysql engine
from sqlalchemy import create_engine
import pymysql
engine = create_engine('mysql+pymysql://' + 'admin' + ':' + '1234mONEYTOr' + '@' + '3.108.47.186' + ':3306/' + 'navi_08_09_2023')
engine.connect()

"""# Normalized Sigma"""

normalised_sigma=pd.DataFrame()

#Getting the working_data from Databases
sql_query='select * from normalised_data'
normalised_df=pd.read_sql_query(sql_query,engine)
normalised_df.shape

normalised_df.columns

columns=['Validated income','Sanction amount','Amount disbursed','Count of previous loans', 'Arbitration',
       'Section 25', 'no of emis paid','tenure_months', 'annual_rate_of_interest', 'current_dpd',
       'first_npa_pos', 'last_npa_pos', 'bureau_score',
       'principal_outstanding_amount', 'interest_outstanding_amount',
       'bounce_fee_pending', 'late_fee_pending', 'penal_interest_pending',
       'penalty_charges_pending', 'Actual DPD (Calculated)', 'Total_Paid',
       'Days_since_disbursal', 'disp_code_NRTP', 'disp_code_address_not_found',
       'disp_code_connectivity_mode_problem', 'disp_code_paid',
       'disp_code_phone_not connected', 'disp_code_positive_response',
       'disp_code_settlement', 'disp_code_special', 'TotalPercentPaid',
       'TimeWeightedTotalPercentPaid', 'Age', 'total_outstanding',
       'state_name', 'gender', 'employment_type',
       'Max_count_dispositionCode_map', 'Last_interaction_sub_type',
       'Last_customer_feedback', 'Last_disp_code_category', 'AgeBracket',
       'DPDSEGMENT', 'EMIsPaidSegmentation','CibilSegmentation','PreviousLoanTakenSegmentation', 'IncomeSegmentation','Count_of_Total_Paid']
normalised_df_1=normalised_df[columns]

normalised_df_1.shape

normalised_df_1.iloc[:,:].mean()

normalised_df_1['Last_Payment_Date'] = pd.to_datetime(normalised_df_1['Last_Payment_Date'])

normalised_df_1.dtypes

normalised_df_1.head(7)

normalised_sigma=(normalised_df_1.iloc[:,:]-normalised_df_1.iloc[:,:].mean())/normalised_df_1.iloc[:,:].std()

normalised_sigma.head()

# normalised_sigma=normalised_sigma.join(normalised_sigma_2)

normalised_df.columns

normalised_sigma.columns

normalised_sigma["loan_account_id"]=normalised_df["loan_account_id"]
normalised_sigma["date"]=normalised_df["date"]
normalised_sigma["account_number"]=normalised_df["account_number"]
normalised_sigma["disbursed_date"]=normalised_df["disbursed_date"]
normalised_sigma["maturity_date"]=normalised_df["maturity_date"]
normalised_sigma["pin_code"]=normalised_df["pin_code"]
normalised_sigma["write_off_date"]=normalised_df["write_off_date"]
normalised_sigma["first_npa_date"]=normalised_df["first_npa_date"]
normalised_sigma["last_npa_date"]=normalised_df["last_npa_date"]
normalised_sigma["date_of_birth"]=normalised_df["date_of_birth"]
normalised_sigma["Last_feedback_date"]=normalised_df["Last_feedback_date"]
normalised_sigma["Last_Payment_Date"]=normalised_df["Last_Payment_Date"]

normalised_df.shape

normalised_sigma.shape

normalised_sigma

normalised_sigma.isna().sum()

normalised_sigma

np.sum(normalised_sigma['Age'])

len(normalised_sigma.columns)

normalised_sigma.columns

Final_selected_Features = ['loan_account_id','account_number','Validated income','Sanction amount','Amount disbursed','Count of previous loans','Arbitration', 'Section 25',
       'no of emis paid', 'tenure_months', 'annual_rate_of_interest', 'current_dpd',
       'first_npa_pos', 'last_npa_pos', 'bureau_score',
       'principal_outstanding_amount', 'interest_outstanding_amount',
       'bounce_fee_pending', 'late_fee_pending', 'penal_interest_pending',
       'penalty_charges_pending', 'Actual DPD (Calculated)', 'Total_Paid',
       'Days_since_disbursal', 'disp_code_NRTP', 'disp_code_address_not_found',
       'disp_code_connectivity_mode_problem', 'disp_code_paid',
       'disp_code_phone_not connected', 'disp_code_positive_response',
       'disp_code_settlement', 'disp_code_special', 'TotalPercentPaid',
       'TimeWeightedTotalPercentPaid', 'Age', 'total_outstanding',
       'state_name', 'gender', 'employment_type',
       'Max_count_dispositionCode_map', 'Last_interaction_sub_type',
       'Last_customer_feedback', 'Last_disp_code_category', 'AgeBracket',
       'DPDSEGMENT','EMIsPaidSegmentation', 'CibilSegmentation','PreviousLoanTakenSegmentation', 'IncomeSegmentation','Count_of_Total_Paid']

# Using Normalised Dataset
normalised_sigma=normalised_sigma[Final_selected_Features]
normalised_sigma.shape

def getNormalisedSigmaBucket(value):
  lowerRange = -5;
  upperRange = 5;

  lowerBucketValue = 0;
  upperBuckerValue = 20;
  sigmaRange = [-5, -4.5, -4, -3.5, -3, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5];
  bucketValues = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20];
  if (value <= lowerRange):
    return lowerBucketValue;
  elif (value >= upperRange):
    return upperBuckerValue;
  else:
    returnValue=0
    i=1
    for i in range(len(sigmaRange)):
      if (value < sigmaRange[i] and value > sigmaRange[i-1]):
        returnValue = bucketValues[i]
        break
    return returnValue;

for x in normalised_sigma.columns:
  if x=="loan_account_id":
    pass
  elif x=='account_number':
    pass
  else:
    s=x+"bucket"
    normalised_sigma[s]=normalised_sigma[x].apply(getNormalisedSigmaBucket)
    #print(normalised_sigma[s])

normalised_sigma

normalised_sigma.to_csv("Navi_2023_09_12_normalised_sigma.csv", index=False)

normalised_sigma.to_sql("normalised_sigma",con=engine, if_exists='replace',index=False)

"""End of Normalised sigma"""